{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pressing-cloud",
   "metadata": {},
   "source": [
    "# Recommendation system for arXiv manuscripts by Peter Boross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "third-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import arxiv\n",
    "import sqlite3\n",
    "import urllib.request as libreq\n",
    "import re\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import itertools\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-transparency",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "educational-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors_LastF(authors):\n",
    "    r = []\n",
    "    for author in authors:\n",
    "        if len(author[1]) == 0: r.append(unidecode.unidecode(author[0]))\n",
    "        else: r.append(unidecode.unidecode(author[0]+author[1][0]))    \n",
    "    return ' '.join(r)\n",
    "\n",
    "def get_authors_LastF_2(authors):\n",
    "    r = []\n",
    "    for authorv in authors:\n",
    "        author = authorv['name'].split(' ')\n",
    "        r.append(unidecode.unidecode(author[-1]+author[0][0]))    \n",
    "    return ' '.join(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-string",
   "metadata": {},
   "source": [
    "### Define categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "local-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'cond-mat', 'cond-mat.mes-hall', 'quant-ph', 'cond-mat.supr-con', 'cond-mat.mtrl-sci', 'cond-mat.str-el', 'cond-mat.other'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-glasgow",
   "metadata": {},
   "source": [
    "### Load manuscripts from arXiv JSON by Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "secondary-ecology",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of papers = 315071\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "with open(\"data/arxiv-metadata-oai-snapshot.json\", \"r\") as f:\n",
    "    for l in f:\n",
    "        d = json.loads(l)\n",
    "        if categories & set(d['categories'].split(' ')):\n",
    "            d['authors_LastF'] = get_authors_LastF(d['authors_parsed'])\n",
    "            articles.append(d)\n",
    "\n",
    "articles_df = pd.DataFrame().from_records(articles)\n",
    "\n",
    "print('number of papers =',len(articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-formula",
   "metadata": {},
   "source": [
    "### Find manuscript of the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quantitative-thong",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of papers of the authors = 90\n"
     ]
    }
   ],
   "source": [
    "authors = ['BorossP','OroszlanyL','PalyiA','AsbothJ','SzechenyiG']\n",
    "\n",
    "ids = list(articles_df[articles_df[\"authors_LastF\"].str.contains('|'.join(authors))]['id'])\n",
    "\n",
    "print('number of papers of the authors =',len(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-netscape",
   "metadata": {},
   "source": [
    "### Find cited papers by prophy.science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "moderate-samuel",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of cited papers of the authors = 1501\n"
     ]
    }
   ],
   "source": [
    "refs=[]\n",
    "\n",
    "for id in ids:\n",
    "    with libreq.urlopen('https://www.prophy.science/api/arxiv/' + id) as url:\n",
    "        refs1paper = json.loads(url.read())\n",
    "    refs.extend([ref['arxivId'] for ref in refs1paper['references'] if ref['arxivId'] != None])\n",
    "\n",
    "refscounted = sorted(Counter(refs).items(), key=lambda pair: pair[1], reverse=True)\n",
    "refs = [entry[0] for entry in refscounted]\n",
    "counts = [entry[1] for entry in refscounted]\n",
    "refscounteddict = dict(zip(refs, counts))\n",
    "\n",
    "print('number of cited papers of the authors =',len(refscounted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-report",
   "metadata": {},
   "source": [
    "### Make training dataset and write it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worth-finnish",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of cited papers which in the selected categories = 1458\n",
      "number of non-cited papers which in the selected categories = 14580\n"
     ]
    }
   ],
   "source": [
    "cited_df = articles_df[articles_df['id'].isin(refs)][['abstract','title','authors_LastF','id']].replace(refscounteddict).rename(columns = {'id': 'citation', 'authors_LastF': 'authors'})\n",
    "cited_df['cited'] = True\n",
    "\n",
    "print('number of cited papers which in the selected categories =',len(cited_df))\n",
    "\n",
    "notcited_df = articles_df[articles_df['id'].isin(refs) == False][['abstract','title','authors_LastF']].sample(n = 10*len(cited_df)).rename(columns = {'authors_LastF': 'authors'})\n",
    "notcited_df['citation'] = 0\n",
    "notcited_df['cited'] = False\n",
    "\n",
    "print('number of non-cited papers which in the selected categories =',len(notcited_df))\n",
    "\n",
    "all_df = pd.concat([cited_df, notcited_df])\n",
    "\n",
    "all_df.to_csv('data/all_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-samoa",
   "metadata": {},
   "source": [
    "### Split to X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dramatic-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_df = pd.read_csv('data/all_df.csv', index_col=0)\n",
    "\n",
    "X = all_df[['authors','title','abstract']]\n",
    "y = list(all_df['cited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-homeless",
   "metadata": {},
   "source": [
    "### Build the model and make cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "refined-labor",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train accuracy =  94.0% test accuracy = 93.5%\ntrain precision =  65.7% test precision = 63.6%\ntrain recall =  72.1% test recall = 68.4%\ntrain roc_auc =  95.6% test roc_auc = 93.3%\n"
     ]
    }
   ],
   "source": [
    "authors_feature = 'authors'\n",
    "authors_transformer = CountVectorizer(lowercase=False, max_features = 1000)\n",
    "\n",
    "title_feature = 'title'\n",
    "title_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1,3), max_features = 2000)\n",
    "\n",
    "abstract_feature = 'abstract'\n",
    "abstract_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1,3), max_features = 5000)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('authors', authors_transformer, authors_feature),\n",
    "        ('title', title_transformer, title_feature),\n",
    "        ('abstract', abstract_transformer, abstract_feature)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', MultinomialNB())])\n",
    "\n",
    "scores = cross_validate(pipeline, X, y, cv=ShuffleSplit(n_splits=5),\n",
    "                        scoring=('accuracy', 'precision', 'recall' , 'roc_auc'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "print('train accuracy = ',\"{:.1f}%\".format(100*np.mean(scores['train_accuracy'])),'test accuracy =',\"{:.1f}%\".format(100*np.mean(scores['test_accuracy'])))\n",
    "print('train precision = ',\"{:.1f}%\".format(100*np.mean(scores['train_precision'])),'test precision =',\"{:.1f}%\".format(100*np.mean(scores['test_precision'])))\n",
    "print('train recall = ',\"{:.1f}%\".format(100*np.mean(scores['train_recall'])),'test recall =',\"{:.1f}%\".format(100*np.mean(scores['test_recall'])))\n",
    "print('train roc_auc = ',\"{:.1f}%\".format(100*np.mean(scores['train_roc_auc'])),'test roc_auc =',\"{:.1f}%\".format(100*np.mean(scores['test_roc_auc'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-angel",
   "metadata": {},
   "source": [
    "### Fit the model and save it"
   ]
  },
  {
   "source": [
    "pipeline.fit(X, y);\n",
    "\n",
    "filename = 'data/model.sav'\n",
    "pickle.dump(pipeline, open(filename, 'wb'))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "source": [
    "### Make a query and predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sonic-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/model.sav'\n",
    "pipeline = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "delta = timedelta(days=1)\n",
    "catstr = '+OR+'.join(['cat:'+x for x in categories])\n",
    "client = arxiv.Client()\n",
    "latest = False\n",
    "n_query = 50\n",
    "start_query = 0\n",
    "last_query = n_query\n",
    "df = pd.DataFrame(columns = ['id','authors', 'title', 'abstract'])\n",
    "\n",
    "while last_query == n_query:\n",
    "    feedparser = client._parse_feed(url='http://export.arxiv.org/api/query?search_query='+catstr+'&start='+str(start_query)+'&max_results='+str(n_query)+'&sortBy=submittedDate')\n",
    "    last_query=0\n",
    "    for entry in feedparser.entries:\n",
    "        if not(latest): latest = datetime.strptime(entry.published[0:10],'%Y-%m-%d')\n",
    "        if latest - datetime.strptime(entry.published[0:10],'%Y-%m-%d') < delta:\n",
    "            last_query+=1\n",
    "            df = df.append({\n",
    "                'id' : entry.id,\n",
    "                'authorsFull' : [author['name'] for author in entry.authors],\n",
    "                'authors' : get_authors_LastF_2(entry.authors),\n",
    "                'title' : entry.title.rstrip(),\n",
    "                'abstract' : entry.summary.rstrip(),\n",
    "                'published': datetime.strptime(entry.published[0:10],'%Y-%m-%d')\n",
    "                            }, ignore_index = True)\n",
    "    start_query += n_query\n",
    "\n",
    "Xnew = df[['authors','title','abstract']]\n",
    "\n",
    "df['rating'] = [x[1] for x in pipeline.predict_proba(Xnew)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "processed-arlington",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   id  published  \\\n",
       "37  http://arxiv.org/abs/2105.14864v1 2021-05-31   \n",
       "50  http://arxiv.org/abs/2105.14763v1 2021-05-31   \n",
       "39  http://arxiv.org/abs/2105.14842v1 2021-05-31   \n",
       "32  http://arxiv.org/abs/2105.14919v1 2021-05-31   \n",
       "28  http://arxiv.org/abs/2105.14941v1 2021-05-31   \n",
       "\n",
       "                                          authorsFull  \\\n",
       "37  [A. Rossi, N. W. Hendrickx, A. Sammak, M. Veld...   \n",
       "50    [Niels John, Adrian Del Maestro, Bernd Rosenow]   \n",
       "39  [Thomas Simons, Alessandro Romito, Dganit Meidan]   \n",
       "32     [Yoonseok Hwang, Jun-Won Rhim, Bohm-Jung Yang]   \n",
       "28             [Huan-Wen Wang, Bo Fu, Shun-Qing Shen]   \n",
       "\n",
       "                                                title  \\\n",
       "37                      Single-Hole Pump in Germanium   \n",
       "50  Robustness of Helical Edge States Under Edge R...   \n",
       "39  Relation between scattering matrix topological...   \n",
       "32  Flat bands with band crossings enforced by sym...   \n",
       "28  Helical Symmetry Breaking and Quantum Anomaly ...   \n",
       "\n",
       "                                             abstract    rating  \n",
       "37  Single-charge pumps are the main candidates fo...  0.806654  \n",
       "50  The helical edge states of time-reversal invar...  0.789467  \n",
       "39  We analyze the conductance of a one-dimensiona...  0.679321  \n",
       "32  Flat bands have band crossing points with othe...  0.291665  \n",
       "28  Helical symmetry of massive Dirac fermions is ...  0.218304  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>published</th>\n      <th>authorsFull</th>\n      <th>title</th>\n      <th>abstract</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>37</th>\n      <td>http://arxiv.org/abs/2105.14864v1</td>\n      <td>2021-05-31</td>\n      <td>[A. Rossi, N. W. Hendrickx, A. Sammak, M. Veld...</td>\n      <td>Single-Hole Pump in Germanium</td>\n      <td>Single-charge pumps are the main candidates fo...</td>\n      <td>0.806654</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>http://arxiv.org/abs/2105.14763v1</td>\n      <td>2021-05-31</td>\n      <td>[Niels John, Adrian Del Maestro, Bernd Rosenow]</td>\n      <td>Robustness of Helical Edge States Under Edge R...</td>\n      <td>The helical edge states of time-reversal invar...</td>\n      <td>0.789467</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>http://arxiv.org/abs/2105.14842v1</td>\n      <td>2021-05-31</td>\n      <td>[Thomas Simons, Alessandro Romito, Dganit Meidan]</td>\n      <td>Relation between scattering matrix topological...</td>\n      <td>We analyze the conductance of a one-dimensiona...</td>\n      <td>0.679321</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>http://arxiv.org/abs/2105.14919v1</td>\n      <td>2021-05-31</td>\n      <td>[Yoonseok Hwang, Jun-Won Rhim, Bohm-Jung Yang]</td>\n      <td>Flat bands with band crossings enforced by sym...</td>\n      <td>Flat bands have band crossing points with othe...</td>\n      <td>0.291665</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>http://arxiv.org/abs/2105.14941v1</td>\n      <td>2021-05-31</td>\n      <td>[Huan-Wen Wang, Bo Fu, Shun-Qing Shen]</td>\n      <td>Helical Symmetry Breaking and Quantum Anomaly ...</td>\n      <td>Helical symmetry of massive Dirac fermions is ...</td>\n      <td>0.218304</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "df[['id','published','authorsFull','title','abstract','rating']].sort_values(by=['rating'],ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'sqlite3' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46ff024f623b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/manuscripts.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CREATE TABLE IF NOT EXISTS manuscipts (id, published, title, abstract, rating)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sqlite3' is not defined"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('data/manuscripts.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('CREATE TABLE IF NOT EXISTS manuscipts (id, published, title, abstract, rating)')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df[['id','published','title','abstract','rating']]\n",
    "\n",
    "dfs.to_sql('MANUSCRIPTS', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fc093823110>"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "c.execute('''  \n",
    "SELECT id FROM MANUSCRIPTS\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd074819d5766a1d2ad05cf1ca12736bfed9e6c5a54bd78b045d29372533f44b271",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}